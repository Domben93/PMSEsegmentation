dataset:
  path_complete: ../Test/dataset/Complete/
  path_train: ../Test/dataset/Train/
  path_validate: ../Test/dataset/Validation/
  path_test: ../Test/dataset/Test/
  max_scale: 2 # max allowed scaling of image
  resize_shape: [ 64, 64 ]  # resize to shape 64x64
  padding_type: 'constant'  # padding mode ['constant', 'reflect', 'replicate' or 'circular'] default constant value: 0

  mean: 9.2158  # if None, it will be calculated. May take a lot of time for big datasets. Only calculated from train dataset
  std: 1.5720  # if None, it will be calculated. May take a lot of time for big datasets. Only calculated from train dataset

model:
  path: ../models/unets.py
  model_type: Unet
  save_path: ../Test/weights/

gpu: cuda:0

model_init:
    pre_trained_weights: null # path pretrained weights e.., ../Test/weights/mateuszbuda-brain-segmentation-pytorch.pt
    freeze_layers: null # layers to freeze. If pretrained weights are unspecified this is ignored (default: all layers)
    random_init: uniform # random initiation type. IGNORED if pretrained weights are specified
    in_channels: 3 # 3 for rgb. Note that
    out_channels: 1 # if in_channels is 1 and pretrained weights has 3 channels channel 1 is chosen
    init_features: 32

dataloader:
  batch_size: 8
  num_workers: 4
  shuffle: True

# Hyper parameters
optimizer:
  loss_type: BinaryDiceLoss
  optim_type: adam #optimizer type
  learning_rate: 0.01 # Initial learning rate
  momentum: 0.9  # Uncomment if wanted to be used. Not available for Adam and some other optimizer algorithms
  weight_decay: 0.0
  betas: [0.5, 0.9]

learning_scheduler:
  step_size: 10 # lr step every n epochs
  gamma: 0.3 # lr = gamma * lr every step_size
  last_epoch: -1 # -1 is for not specified

training:
  number_of_runs: 5
  epochs: 50 # number of epochs
  eval_interval: 1 # Set to None or 0 if no evaluation is wanted
  save_best: True
